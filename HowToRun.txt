

pip install -r requirements.txt


pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121


pip install -e submodules/depth-diff-gaussian-rasterization
pip install -e submodules/simple-knn
pip install numpy==1.26.4
pip install imageio 


# LEGO TEST
python train.py -s test/data/lego --port 6017 --expname "dnerf/lego" --configs arguments/dnerf/lego.py
python export_perframe_3DGS.py --iteration 14000 --configs arguments/dnerf/lego.py --model_path output/dnerf/lego


python train.py -s test/data/bouncingballs --port 6017 --expname "dnerf/bouncingballs" --configs arguments/dnerf/bouncingballs.py
python export_perframe_3DGS.py --iteration 14000 --configs arguments/dnerf/bouncingballs.py --model_path output/dnerf/bouncingballs









# First, extract the frames of each video.
python scripts/preprocess_dynerf.py --datadir data/dynerf/cut_roasted_beef ----<<< fatto? con extract_multicamera_frames???


# Second, generate point clouds from input data.
bash colmap.sh data/dynerf/cut_roasted_beef llff

######## WINDOWS
powershell -File .\run_colmap_process.ps1 -workdir "data/dynerf/cut_roasted_beef" -datatype "llff"



# Third, downsample the point clouds generated in the second step.
python scripts/downsample_point.py data/dynerf/cut_roasted_beef/colmap/dense/workspace/fused.ply data/dynerf/cut_roasted_beef/points3D_downsample2.ply
# Finally, train.
python train.py -s data/dynerf/cut_roasted_beef --port 6017 --expname "dynerf/cut_roasted_beef" --configs arguments/dynerf/cut_roasted_beef.py 







